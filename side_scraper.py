import time
import re
import os
import json
import gspread
from datetime import datetime
from oauth2client.service_account import ServiceAccountCredentials

# ì…€ë ˆë‹ˆì›€ ê´€ë ¨
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# ì„¤ì •
SHEET_URL = "https://docs.google.com/spreadsheets/d/1nKPVCZ6zAOfpqCjV6WfjkzCI55FA9r2yvi9XL3iIneo/edit"
TARGET_GID = 1818966683
SCRAPE_URL = "https://sideproject.co.kr/projects"

# ì§€ì—­ í‚¤ì›Œë“œ
REGION_KEYWORDS = [
    "ì„œìš¸", "ê²½ê¸°", "ì¸ì²œ", "ëŒ€ì „", "ëŒ€êµ¬", "ë¶€ì‚°", "ê´‘ì£¼", "ìš¸ì‚°", "ì„¸ì¢…", 
    "ê°•ì›", "ì¶©ë¶", "ì¶©ë‚¨", "ì „ë¶", "ì „ë‚¨", "ê²½ë¶", "ê²½ë‚¨", "ì œì£¼", "ì˜¨ë¼ì¸"
]

def get_google_sheet():
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds_dict = json.loads(os.environ['GOOGLE_CREDENTIALS'])
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    client = gspread.authorize(creds)
    
    spreadsheet = client.open_by_url(SHEET_URL)
    worksheet = None
    
    for sheet in spreadsheet.worksheets():
        if str(sheet.id) == str(TARGET_GID):
            worksheet = sheet
            break
            
    if worksheet is None:
        raise Exception(f"GIDê°€ {TARGET_GID}ì¸ ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    print(f"ğŸ“‚ ì—°ê²°ëœ ì‹œíŠ¸: {worksheet.title}")
    return worksheet

def get_driver():
    chrome_options = Options()
    
    # [ì¤‘ìš”] ë´‡ íƒì§€ ìš°íšŒ ì˜µì…˜ ì¶”ê°€
    chrome_options.add_argument("--headless") 
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")
    
    # ìë™í™” ì œì–´ ë¬¸êµ¬ ì œê±° (ë´‡ íƒì§€ ë°©ì§€)
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option("useAutomationExtension", False)
    
    # ì¼ë°˜ ì‚¬ìš©ìì²˜ëŸ¼ ë³´ì´ê²Œ User-Agent ì„¤ì •
    user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    chrome_options.add_argument(f"user-agent={user_agent}")
    
    driver = webdriver.Chrome(options=chrome_options)
    
    # navigator.webdriver ì†ì„±ì„ undefinedë¡œ ë³€ê²½ (ìë°”ìŠ¤í¬ë¦½íŠ¸ íƒì§€ ìš°íšŒ)
    driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
        "source": """
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            })
        """
    })
    
    return driver

def get_projects():
    driver = get_driver()
    new_data = []
    today = datetime.now().strftime("%Y-%m-%d")

    try:
        print("ğŸŒ ì‚¬ì´íŠ¸ ì ‘ì† ì¤‘...")
        driver.get(SCRAPE_URL)
        
        # [ìˆ˜ì •] ë¡œë”© ëŒ€ê¸° ì‹œê°„ ë° ë°©ì‹ ë³€ê²½
        try:
            print("â³ ë°ì´í„° ë¡œë”© ëŒ€ê¸° ì¤‘ (ìµœëŒ€ 30ì´ˆ)...")
            # 20ì´ˆ -> 30ì´ˆë¡œ ì—°ì¥
            WebDriverWait(driver, 30).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "a"))
            )
            # í™•ì‹¤í•œ ë Œë”ë§ì„ ìœ„í•´ ê°•ì œ ëŒ€ê¸° ì¶”ê°€
            time.sleep(5) 
            print("âœ… ë¡œë”© ì™„ë£Œ")
        except:
            print("âš ï¸ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼ (ìŠ¤í¬ë¦°ìƒ· ì €ì¥)")
            driver.save_screenshot("error_screenshot.png") # ì—ëŸ¬ ì‹œ ìƒíƒœ í™•ì¸ìš©
            
        # ëª¨ë“  ë§í¬ ìˆ˜ì§‘
        elements = driver.find_elements(By.TAG_NAME, "a")
        print(f"ğŸ” ë°œê²¬ëœ ë§í¬: {len(elements)}ê°œ")

        for elem in elements:
            try:
                raw_link = elem.get_attribute("href")
                if not raw_link: continue

                # ì‚¬ì´ë“œí”„ë¡œì íŠ¸ ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë§ëŠ” ë§í¬ í•„í„°ë§
                if "idx=" in raw_link and "bmode=view" in raw_link:
                    raw_text = elem.text.strip()
                    if not raw_text: continue 

                    lines = raw_text.split('\n')
                    title = lines[0] if lines else raw_text
                    
                    location = "ë¯¸ì •"
                    for keyword in REGION_KEYWORDS:
                        if keyword in raw_text:
                            location = keyword
                            break
                    
                    idx_match = re.search(r'idx=(\d+)', raw_link)
                    if idx_match:
                        idx = idx_match.group(1)
                        full_url = f"https://sideproject.co.kr/projects/?bmode=view&idx={idx}"
                        
                        if not any(d['url'] == full_url for d in new_data):
                            new_data.append({
                                'title': title,
                                'url': full_url,
                                'scraped_at': today,
                                'location': location
                            })
            except:
                continue
                
    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {e}")
    finally:
        driver.quit()
            
    print(f"ğŸ¯ ìˆ˜ì§‘ëœ ê³µê³ : {len(new_data)}ê°œ")
    return new_data

def update_sheet(worksheet, data):
    all_values = worksheet.get_all_values()
    
    if not all_values:
        print("âš ï¸ ì‹œíŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. í—¤ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        headers = ['title', 'url', 'scraped_at', 'status', 'location']
        worksheet.append_row(headers)
        all_values = [headers]
    
    headers = all_values[0]

    try:
        idx_title = headers.index('title')
        idx_url = headers.index('url')
        idx_scraped_at = headers.index('scraped_at')
        idx_status = headers.index('status')
        idx_location = headers.index('location')
    except ValueError as e:
        print(f"â›” í—¤ë” ì˜¤ë¥˜: 1í–‰ì— {e} ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
        return

    existing_urls = set()
    for row in all_values[1:]:
        if len(row) > idx_url:
            existing_urls.add(row[idx_url])

    rows_to_append = []
    for item in data:
        if item['url'] in existing_urls:
            continue
            
        new_row = [''] * len(headers)
        new_row[idx_title] = item['title']
        new_row[idx_url] = item['url']
        new_row[idx_scraped_at] = item['scraped_at']
        new_row[idx_status] = 'archived'
        new_row[idx_location] = item['location']
        
        rows_to_append.append(new_row)

    if rows_to_append:
        print(f"ğŸ“ ë°ì´í„° ì“°ê¸° ì‹œì‘... (ì´ {len(rows_to_append)}ê±´)")
        worksheet.append_rows(rows_to_append)
        print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ!")
    else:
        print("â„¹ï¸ ìƒˆë¡œìš´ ê³µê³  ì—†ìŒ.")

if __name__ == "__main__":
    try:
        sheet = get_google_sheet()
        projects = get_projects()
        update_sheet(sheet, projects)
    except Exception as e:
        print(f"ğŸš¨ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
