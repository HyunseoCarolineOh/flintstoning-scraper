import os, time, json, re
import gspread
from datetime import datetime
from oauth2client.service_account import ServiceAccountCredentials
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# [ì„¤ì •] ì´ íŒŒì¼ ì „ìš© ì •ë³´
CONFIG = {
    "name": "ì‚¬ì´ë“œí”„ë¡œì íŠ¸",
    "url": "https://sideproject.co.kr/projects",
    "gid": "1818966683" # íƒ­ ê³ ìœ  ë²ˆí˜¸
}

# [ê³µí†µ] ì‹œíŠ¸ ì—°ê²° (GIDë¡œ ì°¾ê¸°)
def get_worksheet():
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds_dict = json.loads(os.environ['GOOGLE_CREDENTIALS'])
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    client = gspread.authorize(creds)
    spreadsheet = client.open_by_url("https://docs.google.com/spreadsheets/d/1nKPVCZ6zAOfpqCjV6WfjkzCI55FA9r2yvi9XL3iIneo/edit")
    # ìˆœì„œê°€ ë°”ë€Œì–´ë„ IDë¡œ íƒ­ì„ ì°¾ìŒ
    sheet = next((s for s in spreadsheet.worksheets() if str(s.id) == CONFIG["gid"]), None)
    if not sheet: raise Exception(f"{CONFIG['gid']} ì‹œíŠ¸ë¥¼ ëª» ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    return sheet

def get_driver():
    options = Options()
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    # ì°½ í¬ê¸° ì¶”ê°€ (ìš”ì†Œê°€ ìˆ¨ê²¨ì§€ëŠ” ê²ƒ ë°©ì§€)
    options.add_argument("--window-size=1920,1080") 
    
    user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
    options.add_argument(f"user-agent={user_agent}")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option("useAutomationExtension", False)
    
    driver = webdriver.Chrome(options=options)
    
    # 3. ë¸Œë¼ìš°ì € ì§€ë¬¸ ë³€ì¡°
    driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
        "source": """
            Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
            window.chrome = { runtime: {} };
            Object.defineProperty(navigator, 'languages', {get: () => ['ko-KR', 'ko', 'en-US', 'en']});
        """
    })
    return driver

# [ì „ìš©] ë°ì´í„° ìˆ˜ì§‘
def scrape_projects():
    driver = get_driver()
    new_data = []
    today = datetime.now().strftime("%Y-%m-%d")
    regions = ["ì„œìš¸", "ê²½ê¸°", "ì¸ì²œ", "ëŒ€ì „", "ëŒ€êµ¬", "ë¶€ì‚°", "ê´‘ì£¼", "ìš¸ì‚°", "ì„¸ì¢…", "ê°•ì›", "ì¶©ë¶", "ì¶©ë‚¨", "ì „ë¶", "ì „ë‚¨", "ê²½ë¶", "ê²½ë‚¨", "ì œì£¼", "ì˜¨ë¼ì¸"]

    try:
        print(f"ðŸŒ {CONFIG['url']} ì ‘ì† ì¤‘...")
        driver.get(CONFIG["url"])
        
        # 1. íŽ˜ì´ì§€ ë³¸ë¬¸(body)ì´ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        wait = WebDriverWait(driver, 20)
        wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))
        
        # 2. ì‚¬ì´íŠ¸ì˜ ë™ì  ë¡œë”©(JS)ì„ ìœ„í•´ ì¶©ë¶„í•œ ì‹œê°„ ëŒ€ê¸°
        # sideproject.co.krëŠ” ë¦¬ìŠ¤íŠ¸ê°€ ë¡œë”©ë˜ëŠ” ë° ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
        time.sleep(7)
        
        # 3. ëª¨ë“  a íƒœê·¸ ìˆ˜ì§‘
        elements = driver.find_elements(By.TAG_NAME, "a")
        print(f"ðŸ” ë°œê²¬ëœ ë§í¬ ìˆ˜: {len(elements)}ê°œ")

        for elem in elements:
            try:
                href = elem.get_attribute("href")
                
                # ìƒì„¸ íŽ˜ì´ì§€ ë§í¬ íŒ¨í„´ í™•ì¸ (idxì™€ bmode=view í¬í•¨ ì—¬ë¶€)
                if href and "idx=" in href and "bmode=view" in href:
                    text = elem.text.strip()
                if not text: continue
                
                # ì§€ì—­ì„ ì°¾ìœ¼ë©´ í•´ë‹¹ ì§€ì—­ëª…ì„, ëª» ì°¾ìœ¼ë©´ ë¹ˆ ë¬¸ìžì—´("")ì„ í• ë‹¹í•©ë‹ˆë‹¤.
                loc = next((k for k in regions if k in text), "") 
                
                idx = re.search(r'idx=(\d+)', href).group(1)
                full_url = f"https://sideproject.co.kr/projects/?bmode=view&idx={idx}"
                
                if not any(d['url'] == full_url for d in new_data):
                    new_data.append({
                        'title': text.split('\n')[0], 
                        'url': full_url, 
                        'scraped_at': today, 
                        'location': loc
                    })
    finally: 
        driver.quit()
    return new_data

# [ê³µí†µ] ìŠ¤ë§ˆíŠ¸ ì €ìž¥ (í—¤ë” ì´ë¦„ ê¸°ì¤€)
def update_sheet(ws, data):
    if not data: return print(f"[{CONFIG['name']}] ìƒˆ ê³µê³  ì—†ìŒ")
    all_v = ws.get_all_values()
    headers = all_v[0] if all_v else ['title', 'url', 'scraped_at', 'status', 'location']
    col_map = {name: i for i, name in enumerate(headers)}
    existing_urls = {row[col_map['url']] for row in all_v[1:] if len(row) > col_map['url']}
    
    rows = []
    for item in data:
        if item['url'] in existing_urls: continue
        row = [''] * len(headers)
        for k, v in item.items():
            if k in col_map: row[col_map[k]] = v
        if 'status' in col_map: row[col_map['status']] = 'archived'
        rows.append(row)
    
    if rows: ws.append_rows(rows); print(f"ðŸ’¾ {CONFIG['name']} {len(rows)}ê±´ ì €ìž¥")

if __name__ == "__main__":
    ws = get_worksheet(); data = scrape_projects(); update_sheet(ws, data)
