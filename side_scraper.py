import time
import json
import os
import pandas as pd
import gspread
from gspread_dataframe import set_with_dataframe, get_as_dataframe
from google.oauth2.service_account import Credentials
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from datetime import datetime

# ==========================================
# 1. êµ¬ê¸€ ì‹œíŠ¸ ì¸ì¦
# ==========================================
json_creds = json.loads(os.environ['GOOGLE_CREDENTIALS'])
scope = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
creds = Credentials.from_service_account_info(json_creds, scopes=scope)
gc = gspread.authorize(creds)

def save_to_sheet(sheet_url, new_data):
    try:
        if 'gid=' in sheet_url:
            target_gid = int(sheet_url.split('gid=')[1].split('#')[0])
            doc = gc.open_by_url(sheet_url)
            worksheet = next((ws for ws in doc.worksheets() if ws.id == target_gid), None)
        else:
            doc = gc.open_by_url(sheet_url)
            worksheet = doc.get_worksheet(0)
            
        if not worksheet:
            print("[ì‚¬ì´ë“œ] íƒ­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        existing_df = get_as_dataframe(worksheet, header=0)
        existing_data_count = len(existing_df.dropna(how='all'))
        next_row = existing_data_count + 2
        
        try:
            existing_urls = worksheet.col_values(3)[1:]
        except:
            existing_urls = []

        final_data = []
        for item in new_data:
            if item['url'] not in existing_urls:
                final_data.append(item)
        
        if final_data:
            df = pd.DataFrame(final_data)
            set_with_dataframe(worksheet, df, row=next_row, include_column_header=False)
            print(f"[ì‚¬ì´ë“œ] {len(final_data)}ê°œ ì €ì¥ ì™„ë£Œ!")
        else:
            print("[ì‚¬ì´ë“œ] ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"[ì‚¬ì´ë“œ] ì €ì¥ ì‹¤íŒ¨: {e}")

# ==========================================
# 2. ë¸Œë¼ìš°ì € ì„¤ì • (ê°•í™”ë¨)
# ==========================================
options = Options()
options.add_argument('--headless')
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')
# ìµœì‹  ë§¥ë¶ í¬ë¡¬ìœ¼ë¡œ ìœ„ì¥
options.add_argument("user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
options.add_argument("--window-size=1920,1080")

driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
today_date = datetime.now().strftime('%Y-%m-%d')

# ==========================================
# 3. ì‚¬ì´ë“œ í”„ë¡œì íŠ¸ ìˆ˜ì§‘ (ëŒ€ê¸° ë¡œì§ ì¶”ê°€)
# ==========================================
print("â–¶ ì‚¬ì´ë“œ í”„ë¡œì íŠ¸ ì ‘ì† ì¤‘...")
driver.get("https://sideproject.co.kr/projects")

# [í•µì‹¬] ë°ì´í„°ê°€ ë¡œë”©ë  ë•Œê¹Œì§€ ìµœëŒ€ 20ì´ˆ ê¸°ë‹¤ë¦¼
try:
    WebDriverWait(driver, 20).until(
        EC.presence_of_element_located((By.TAG_NAME, "a"))
    )
    print("âœ… ì‚¬ì´íŠ¸ ë¡œë”© ì„±ê³µ!")
except:
    print("âš ï¸ ë¡œë”© ì‹œê°„ ì´ˆê³¼ (ê·¸ë˜ë„ ì§„í–‰í•´ë´…ë‹ˆë‹¤)")

time.sleep(5)

# ìŠ¤í¬ë¡¤ 3ë²ˆ ê°•í•˜ê²Œ ë‚´ë¦¬ê¸°
for _ in range(3):
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(3)

side_data = []
all_links = driver.find_elements(By.TAG_NAME, "a")

print(f"ğŸ” ë°œê²¬ëœ ì „ì²´ ë§í¬ ìˆ˜: {len(all_links)}ê°œ")

for link in all_links:
    try:
        url = link.get_attribute("href")
        title = link.text.strip()
        
        # ì œëª©ì´ ìˆê³ , ê¸¸ì´ê°€ 7ì ì´ìƒì¸ ê²ƒë§Œ
        if url and title and len(title) > 7:
            # ì œì™¸ ë‹¨ì–´ í•„í„°ë§
            ignore_words = ["ë¡œê·¸ì¸", "íšŒì›ê°€ì…", "ë§ˆì´í˜ì´ì§€", "ê³µì§€ì‚¬í•­", "ì´ìš©ì•½ê´€", "ê°œì¸ì •ë³´", "ë¹„ë°€ë²ˆí˜¸", "ê¸€ì“°ê¸°"]
            if any(word in title for word in ignore_words):
                continue
            
            # ë¦¬ìŠ¤íŠ¸ ì¤‘ë³µ ë°©ì§€
            if not any(d['url'] == url for d in side_data):
                side_data.append({
                    'title': title,
                    'subtitle': '',
                    'url': url,
                    'created_at': today_date,
                    'company': '',
                    'status': 'archived',
                    'publish': ''
                })
    except:
        continue

print(f"âœ… ìµœì¢… ìˆ˜ì§‘ ê°œìˆ˜: {len(side_data)}ê°œ")

# â–¼â–¼â–¼ ì‹œíŠ¸ ì£¼ì†Œ í™•ì¸ â–¼â–¼â–¼
sheet_url = 'https://docs.google.com/spreadsheets/d/1nKPVCZ6zAOfpqCjV6WfjkzCI55FA9r2yvi9XL3iIneo/edit?gid=1818966683#gid=1818966683'
save_to_sheet(sheet_url, side_data)

driver.quit()
