import os, time, json, re
import gspread
from datetime import datetime
from oauth2client.service_account import ServiceAccountCredentials
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# [ì„¤ì •] ì´ íŒŒì¼ ì „ìš© ì •ë³´
CONFIG = {
    "name": "ì˜¤í¼ì„¼íŠ¸",
    "url": "https://offercent.co.kr/company-list?jobCategories=0040002%2C0170004",
    "gid": "639559541" # ì˜¤í¼ì„¼íŠ¸ íƒ­ GID
}

# [ê³µí†µ] ì‹œíŠ¸ ì—°ê²° (GIDë¡œ ì°¾ê¸°)
def get_worksheet():
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    # GitHub Actionsì˜ Secrets ë“±ì— ì €ì¥ëœ JSON ì¸ì¦ ì •ë³´ ë¡œë“œ
    creds_dict = json.loads(os.environ['GOOGLE_CREDENTIALS'])
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    client = gspread.authorize(creds)
    spreadsheet = client.open_by_url("https://docs.google.com/spreadsheets/d/1nKPVCZ6zAOfpqCjV6WfjkzCI55FA9r2yvi9XL3iIneo/edit")
    
    # GIDë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì›Œí¬ì‹œíŠ¸ ì„ íƒ (íƒ­ ì´ë¦„ ë³€ê²½ ëŒ€ë¹„)
    sheet = next((s for s in spreadsheet.worksheets() if str(s.id) == CONFIG["gid"]), None)
    if not sheet: raise Exception(f"{CONFIG['gid']} ì‹œíŠ¸ë¥¼ ëª» ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    return sheet

# [ê³µí†µ] ë¸Œë¼ìš°ì € ì‹¤í–‰ ì„¤ì •
def get_driver():
    options = Options()
    options.add_argument("--headless") # ì°½ ì—†ì´ ì‹¤í–‰
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-blink-features=AutomationControlled")
    driver = webdriver.Chrome(options=options)
    # ë´‡ íƒì§€ ìš°íšŒ ì„¤ì •
    driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
        "source": "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"
    })
    return driver

# [ì „ìš©] ë°ì´í„° ìˆ˜ì§‘ - ë¡œë”© ëŒ€ê¸° ë¡œì§ ê°•í™” ë²„ì „
def scrape_projects():
    driver = get_driver()
    new_data = []
    today = datetime.now().strftime("%Y-%m-%d")
    urls_check = set()
    
    try:
        driver.get(CONFIG["url"])
        
        # [ê°œì„  2] ëª…ì‹œì  ëŒ€ê¸°(Explicit Wait) ì„¤ì •
        # 20ì´ˆ ë™ì•ˆ 'job' ë§í¬ë¥¼ ê°€ì§„ ê³µê³  ì¹´ë“œê°€ ìµœì†Œ 1ê°œ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
        wait = WebDriverWait(driver, 20)
        try:
            print("â³ ê³µê³  ë°ì´í„° ë¡œë”© ëŒ€ê¸° ì¤‘...")
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "a[href*='/job/']")))
            # ìš”ì†Œê°€ ë°œê²¬ëœ í›„ì—ë„ ë ˆì´ì•„ì›ƒì´ ì™„ì „íˆ ì¡íˆë„ë¡ ë¬¼ë¦¬ì  ì‹œê°„ì„ ì•½ê°„ ë” ì¤ë‹ˆë‹¤.
            time.sleep(3) 
            print("âœ… ë¡œë”© ì™„ë£Œ: ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
        except:
            # íƒ€ì„ì•„ì›ƒ ë°œìƒ ì‹œ ì—ëŸ¬ë¥¼ ë‚´ì§€ ì•Šê³  ìˆ˜ì§‘ ì‹œë„ (ì´ë¯¸ ë¡œë”©ë˜ì—ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
            print("âš ï¸ ë¡œë”© ëŒ€ê¸° ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. í˜„ì¬ ìƒíƒœì—ì„œ ìˆ˜ì§‘ì„ ì‹œë„í•©ë‹ˆë‹¤.")
            
        # ìŠ¤í¬ë¡¤ ë° ìˆ˜ì§‘ ë°˜ë³µ
        for _ in range(10):
            # cards ì •ì˜ (NameError ë°©ì§€)
            cards = driver.find_elements(By.TAG_NAME, "a")
            
            for card in cards:
                href = card.get_attribute("href")
                if not href or "/job/" not in href: continue
                
                try:
                    # ê¸°ì¡´ì— í™•ì¸í•œ data-variant="body-02" ê¸°ì¤€ ìˆ˜ì§‘
                    elements = card.find_elements(By.CSS_SELECTOR, 'span[data-variant="body-02"]')
                    if not elements: continue

                    texts = [el.text.strip() for el in elements if el.text.strip()]
                    
                    if len(texts) >= 2:
                        company = texts[0]
                        titles = texts[1:]
                        
                        for title in titles:
                            # ë‚ ì§œ ì •ë³´ í•„í„°ë§
                            if any(x in title for x in ["ì „", "ê°œì›”", "ì¼", "ì£¼"]): continue
                            
                            data_id = f"{href}_{title}"
                            if data_id not in urls_check:
                                new_data.append({
                                    'company': company,
                                    'title': title,
                                    'url': href,
                                    'scraped_at': today
                                })
                                urls_check.add(data_id)
                except:
                    continue
            
            # ìŠ¤í¬ë¡¤ í›„ ìƒˆë¡œìš´ ì½˜í…ì¸  ë¡œë”© ëŒ€ê¸°
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(3) 

    finally: 
        driver.quit()
    
    print(f"ğŸ“Š ìµœì¢… ìˆ˜ì§‘ëœ ê±´ìˆ˜: {len(new_data)}ê±´")
    return new_data
    
# [ê³µí†µ] ì‹œíŠ¸ ë°ì´í„° ì—…ë°ì´íŠ¸
def update_sheet(ws, data):
    if not data: 
        print(f"[{CONFIG['name']}] ìƒˆë¡œ ìˆ˜ì§‘ëœ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    all_v = ws.get_all_values()
    headers = all_v[0] if all_v else ['company', 'title', 'url', 'scraped_at', 'status']
    
    # í—¤ë” ì¸ë±ìŠ¤ ë§¤í•‘
    col_map = {name: i for i, name in enumerate(headers)}
    # ê¸°ì¡´ ì‹œíŠ¸ì— ì €ì¥ëœ URL ëª©ë¡ (ì¤‘ë³µ ì €ì¥ ë°©ì§€ìš©)
    existing_urls = {row[col_map['url']] for row in all_v[1:] if len(row) > col_map['url']}
    
    rows_to_append = []
    for item in data:
        # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” URLì€ ì œì™¸
        if item['url'] in existing_urls: continue
        
        # í—¤ë” ìˆœì„œì— ë§ì¶° ë¦¬ìŠ¤íŠ¸ ìƒì„±
        row = [''] * len(headers)
        for k, v in item.items():
            if k in col_map: row[col_map[k]] = v
        
        # ìƒíƒœê°’ ê¸°ë³¸ ì„¤ì • (ì˜ˆ: archived)
        if 'status' in col_map: row[col_map['status']] = 'new'
        
        rows_to_append.append(row)
    
    if rows_to_append:
        ws.append_rows(rows_to_append)
        print(f"ğŸ’¾ {CONFIG['name']} ì‹ ê·œ ê³µê³  {len(rows_to_append)}ê±´ ì €ì¥ ì™„ë£Œ")
    else:
        print(f"[{CONFIG['name']}] ì‹œíŠ¸ì— ì´ë¯¸ ëª¨ë‘ ë°˜ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

# ë©”ì¸ ì‹¤í–‰ë¶€
if __name__ == "__main__":
    try:
        ws = get_worksheet()
        data = scrape_projects()
        update_sheet(ws, data)
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
