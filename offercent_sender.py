import os
import json
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import pandas as pd
import requests
from bs4 import BeautifulSoup
from openai import OpenAI
import re

# =========================================================
# 1. ì„¤ì • ë° ì¸ì¦ [Common: ê³µí†µ í™˜ê²½ ì„¤ì •]
# =========================================================
def main():
    try:
        print("--- [Offercent Sender] ì‹œì‘ ---")
        
        # [Common] API í‚¤ ë° í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (ë³´ì•ˆì„ ìœ„í•´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
        if 'GOOGLE_CREDENTIALS' not in os.environ:
            raise ValueError("GOOGLE_CREDENTIALS í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if 'OPENAI_API_KEY' not in os.environ:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if 'SLACK_WEBHOOK_URL' not in os.environ:
            raise ValueError("SLACK_WEBHOOK_URL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        json_creds = os.environ['GOOGLE_CREDENTIALS']
        creds_dict = json.loads(json_creds)
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        client = gspread.authorize(creds)

        # [Common] êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì ‘ê·¼ ë° ë°ì´í„° ë¡œë“œ
        spreadsheet = client.open('í”Œë¦°íŠ¸ìŠ¤í† ë‹ ì†Œì¬ DB') 
        sheet = spreadsheet.get_worksheet(3) # ë„¤ ë²ˆì§¸ íƒ­
        data = sheet.get_all_values()
        
        if not data:
            print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        headers = data.pop(0)
        df = pd.DataFrame(data, columns=headers)

        # =========================================================
        # 2. í•„í„°ë§ ë¡œì§ [Common: ë°œì†¡ ëŒ€ìƒ ì„ ë³„]
        # =========================================================
        # Fì—´(ìƒíƒœ)ì´ 'archived'ì´ê³  publish ì—´ì´ 'TRUE'ì¸ í–‰ë§Œ ì¶”ì¶œ
        if len(df.columns) <= 5:
            print("ì—´ ê°œìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (Fì—´ í•„ìš”)")
            return

        col_status_name = df.columns[5] 
        condition = (df[col_status_name].str.strip() == 'archived') & (df['publish'].str.strip() == 'TRUE')
        target_rows = df[condition]

        if target_rows.empty:
            print("ë°œì†¡í•  ëŒ€ìƒ(archived & publish=TRUE)ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ê°€ì¥ ìœ„ì— ìˆëŠ” í•œ ê°œì˜ í–‰ë§Œ ì²˜ë¦¬
        row = target_rows.iloc[0]
        update_row_index = row.name + 2 
        
        # [Common] ê¸°ë³¸ ë°ì´í„° ë³€ìˆ˜ í• ë‹¹
        project_title = row['title']
        target_url = row['url']
        company_name = row.get('company', 'Company')

        # =========================================================
        # 3. ì›¹ ìŠ¤í¬ë˜í•‘ [Offercent Specific: ì‚¬ì´íŠ¸ êµ¬ì¡° ë§ì¶¤ ì¶”ì¶œ]
        # =========================================================
        print(f"--- [Offercent] ìŠ¤í¬ë˜í•‘ ì‹œì‘: {target_url} ---")
        headers_ua = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        
        try:
            response = requests.get(target_url, headers=headers_ua, timeout=15)
            response.raise_for_status()
        except Exception as e:
            print(f"âŒ ì ‘ì† ì‹¤íŒ¨: {e}")
            return

        soup = BeautifulSoup(response.text, 'html.parser')

        # [Offercent Specific] ì˜¤í¼ì„¼íŠ¸ì˜ ë³¸ë¬¸ ì˜ì—­(main, article ë“±)ì„ íƒ€ê²ŸíŒ…
        content_area = soup.find('main') or soup.find('article') or soup.find('div', {'class': 'description'})
        if not content_area:
            content_area = soup

        # [Common] í…ìŠ¤íŠ¸ ì •ì œ: ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±° ë° ê³µë°± í†µí•©
        for tag in content_area(['script', 'style', 'nav', 'footer', 'iframe']):
            tag.extract()

        full_text = content_area.get_text(separator="\n", strip=True)
        cleaned_text = re.sub(r'\n+', '\n', full_text) # [Common] í† í° ì ˆì•½ì„ ìœ„í•´ ì—°ì† ì¤„ë°”ê¿ˆ ì œê±°
        truncated_text = cleaned_text[:6000] 

        # =========================================================
        # 4. GPT ë¸Œëœë“œ ì í•©ì„± íŒë‹¨ ë° ìš”ì•½ [Common: AI íë ˆì´ì…˜]
        # =========================================================
        print("--- GPT ë¸Œëœë“œ ì í•©ì„± íŒë‹¨ ë° ë¶„ì„ ìš”ì²­ ---")
        client_openai = OpenAI(api_key=os.environ['OPENAI_API_KEY'])

        # [Common] ì œì™¸ ì¡°ê±´ ë° ë¸Œëœë“œ ê°€ì´ë“œë¼ì¸ ì„¤ì •
        exclude_positions = "ì¸í”Œë£¨ì–¸ì„œ ë§ˆì¼€íŒ…, í¼í¬ë¨¼ìŠ¤ ë§ˆì¼€íŒ…, ê·¸ë¡œìŠ¤ í•´í‚¹/ê·¸ë¡œìŠ¤ ë§ˆì¼€íŒ… ê´€ë ¨ ëª¨ë“  í¬ì§€ì…˜"

        gpt_prompt = f"""
        ë„ˆëŠ” ìŠ¤íƒ€íŠ¸ì—… ì±„ìš© ì •ë³´ë¥¼ ìš°ë¦¬ ë¸Œëœë“œ ê°€ì´ë“œì— ë§ì¶° ì„ ë³„í•˜ëŠ” ì „ë¬¸ ì—ë””í„°ì•¼.

        [í•„í„°ë§ ê·œì¹™]
        - ë‹¤ìŒ ì§êµ°ì— í•´ë‹¹í•˜ë©´ ë°˜ë“œì‹œ 'is_suitable': falseë¡œ ì²˜ë¦¬í•´: {exclude_positions}
        - ìœ„ ì§êµ°ì´ ì•„ë‹ˆê³ , ì¼ë°˜ì ì¸ ê¸°íš, ê°œë°œ, ë””ìì¸, ì „ëµ ë“± ë¸Œëœë“œì— ì í•©í•œ ì§êµ°ì´ë©´ trueë¡œ ì²˜ë¦¬í•´.

        [ì§€ì‹œ ì‚¬í•­]
        ì•„ë˜ [ì±„ìš© ê³µê³  ë³¸ë¬¸]ì„ ì½ê³  JSON í¬ë§·ìœ¼ë¡œ ì‘ë‹µí•´ì¤˜.
        1. **is_suitable**: ì í•© ì—¬ë¶€ (true/false)
        2. **reason**: ì í•©/ë¶€ì í•© íŒë‹¨ ì´ìœ  (í•œ ë¬¸ì¥)
        3. **required_exp**: ê²½ë ¥ ìš”ê±´ (ì˜ˆ: 3ë…„ ì´ìƒ, ë¬´ê´€ ë“±)
        4. **summary**: (ì í•©í•  ê²½ìš°ë§Œ) 'í•´ìš”'ì²´ë¡œ ì‘ì„±í•œ ë§¤ë ¥ì ì¸ 2~3ë¬¸ì¥ ìš”ì•½.

        [ì±„ìš© ê³µê³  ë³¸ë¬¸]
        {truncated_text}
        """

        try:
            completion = client_openai.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ë©°, ì œì™¸ ì§êµ° ì—¬ë¶€ë¥¼ ì—„ê²©íˆ íŒë‹¨í•˜ì„¸ìš”."},
                    {"role": "user", "content": gpt_prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.3,
            )
            
            gpt_data = json.loads(completion.choices[0].message.content)
            is_suitable = gpt_data.get('is_suitable', False)
            reason = gpt_data.get('reason', 'íŒë‹¨ ê·¼ê±° ì—†ìŒ')
            extracted_exp = gpt_data.get('required_exp', 'ë³¸ë¬¸ í™•ì¸')
            extracted_summary = gpt_data.get('summary', '')

        except Exception as e:
            print(f"âš ï¸ GPT ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return

        # =========================================================
        # 5. ë¶„ê¸° ì²˜ë¦¬ ë° ê²°ê³¼ ë°œì†¡ [Common: ì¡°ê±´ë³„ ì‚¬í›„ ì²˜ë¦¬]
        # =========================================================
        
        # [Case 1] ë¸Œëœë“œ ë¶€ì í•© í¬ì§€ì…˜ì¼ ê²½ìš°
        if not is_suitable:
            print(f"â© [ì œì™¸ ëŒ€ìƒ] {reason}")
            sheet.update_cell(update_row_index, 6, 'excluded') # ì‹œíŠ¸ ìƒíƒœë¥¼ 'excluded'ë¡œ ë³€ê²½
            return

        # [Case 2] ì í•©í•œ í¬ì§€ì…˜ì¼ ê²½ìš° ìŠ¬ë™ ì „ì†¡
        slack_message = (
            f"*<ì˜¤ëŠ˜ ì˜¬ë¼ì˜¨ ì±„ìš© ê³µê³ >*\n\n"
            f"*{project_title}*\n\n"
            f"*ê¸°ì—…ëª…:* {company_name}\n"
            f"*ì—°ì°¨:* {extracted_exp}\n\n"
            f"*ìš”ì•½*\n{extracted_summary}\n\n"
            f"ğŸ”— <{target_url}|ê³µê³  ë°”ë¡œê°€ê¸°>"
        )

        print("--- ìŠ¬ë™ ì „ì†¡ ì‹œì‘ ---")
        webhook_url = os.environ['SLACK_WEBHOOK_URL']
        slack_res = requests.post(webhook_url, json={"text": slack_message})

        if slack_res.status_code == 200:
            print("âœ… ìŠ¬ë™ ì „ì†¡ ì„±ê³µ!")
            sheet.update_cell(update_row_index, 6, 'published') # ì‹œíŠ¸ ìƒíƒœë¥¼ 'published'ë¡œ ë³€ê²½
            print("âœ… ìƒíƒœ ë³€ê²½ ì™„ë£Œ (archived -> published)")
        else:
            print(f"âŒ ìŠ¬ë™ ì „ì†¡ ì‹¤íŒ¨: {slack_res.status_code}")

    except Exception as e:
        print(f"\nâŒ ì‹œìŠ¤í…œ ì—ëŸ¬ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()
